{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8018f197",
   "metadata": {},
   "source": [
    "- Andrea De Vita\n",
    "- Enrico Lupi\n",
    "- Manfredi Miranda\n",
    "- Francesco Zane\n",
    "\n",
    "-----------------------\n",
    "\n",
    "# Streaming Processing of the QUAX Experiment Data for the Detection of Galactic Axions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b81bd98",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "\n",
    "The axion is a hypothetical particle introduced to solve the strong CP problem of Quantum Chromo Dynamics. It is speculated that axions may also constitute the dark matter (DM) content in our galaxy. The [QUAX](https://www.pd.infn.it/eng/quax/) (QUaerere AXions) experiment aims at detecting this particle by using a copper cavity immersed in a static magnetic field of 8.1 T, cooled down at a working temperature of about 150 mK.\n",
    "\n",
    "The goal of this project is to create a quasi real-time processing chain of the data produced by the QUAX experimental apparatus and a live monitoring system of the detector data, using [Apache Kafka](https://kafka.apache.org/) and [Apache Spark](https://spark.apache.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25ac8d9",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. [Introduction](#introduction) <br>\n",
    "    1.1. [Experiment](#intro_experiment) <br>\n",
    "    1.2. [Data Structure](#intro_data_structure) <br>\n",
    "    1.3. [Cluster](#intro_cluster) <br>\n",
    "2. [Data Processing](#processing) <br>\n",
    "    2.1. [Pipeline Overview](#pipeline) <br>\n",
    "    2.2. [Kafka - Receiving Data from DAQ](#kafka) <br> \n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.2.1. [Data Topic](#kafka_topic) <br>\n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.2.2. [Data Pre-processing](#kafka_preprocessing) <br>\n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.2.3. [Producer](#kafka_producer) <br>\n",
    "    2.3. [Spark - Distributed Processing](#spark) <br>\n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.2.1. [FFT](#spark_fft) <br>\n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.2.1. [Output Message](#spark_output) <br>\n",
    "    2.4. [Live Plot](#live_plot) <br>\n",
    "3. [Performance Tests](#test) <br>\n",
    "    3.1. [Kafka](#test_kafka) <br>\n",
    "    3.2. [Spark](#test_spark) <br>\n",
    "4. [Conclusion](#conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398118cf",
   "metadata": {},
   "source": [
    "## 1. Introduction <a name=\"introduction\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa93b89",
   "metadata": {},
   "source": [
    "### 1.1. Experiment <a name=\"intro_experiment\"></a>\n",
    "\n",
    "\n",
    "![quax lab](Images\\labQuax.webp)\n",
    "\n",
    "The QUAX experiment aims at the axion detection by using a copper cavity immersed in a static magnetic field of 8.1T, cooled down at a working temperature of about 150mK. The axion is expected to couple with the spin of the electron, interacting with the cavity and inducing a radio-frequency that can be sensed via a Josephson parametric amplifier. For a given configuration of the RF cavity, a scan of the phase of the electromagnetic field is performed to be able to possibly identify a localised excess, a hint of the coupling of an axion with the photon. \n",
    "\n",
    "The data acquisition system of the QUAX experiment generates two streams of digitized reading of the amplifiers, representing the real and imaginary components of the measured phase. To improve the signal over noise ratio, a QUAX data-taking run extends over a long time (up to weeks), repeating the scans over multiple times. Data are saved locally on the DAQ servers in the form of binary files, each corresponding to a multitude of continuous scans performed in the entire frequency range. A single pair of raw files is thus representative of only a few seconds of data taking, but are already including several (thousands) scans. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe23e5c",
   "metadata": {},
   "source": [
    "### 1.2. Data Structure <a name=\"intro_data_structure\"></a>\n",
    "\n",
    "The dataset is composed of 2 sets (named duck_i and duck_q respectively) of .dat binary files, each one comprised of a continuous series of ADC readings from the amplifier. Each ADC reading is written in the raw files as a 32 bit floating point value. The ADC readout frequency is 2 × 10<sup>6</sup> Hz (2 MegaSample per second, or 2MS/s), thus resulting in a raw data throughput of 128 Mbps (16 MB/s). During data taking the readouts are formatted in .dat file such that each file is comprised of 8193 × 2<sup>10</sup> samples. This results in producing a pair of .dat files (duck_i and duck_q) every 4.2 s.\n",
    "\n",
    "The dataset is provided on a cloud storage s3 bucket hosted on Cloud Veneto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf733f7",
   "metadata": {},
   "source": [
    "### 1.3. Cluster <a name=\"intro_cluster\"></a>\n",
    "\n",
    "This project has been done on a cluster composed by 4 virtual machines, each with 4 VCPUs with 25 GB disk space and 8 GB RAM each. The virtual machines are hosted on [CloudVeneto](https://cloudveneto.it/), an OpenStack-based cloud managed by University of Padova and INFN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd5355d",
   "metadata": {},
   "source": [
    "## 2. Data Processing <a name=\"processing\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c6d1aa",
   "metadata": {},
   "source": [
    "The processing of the raw data is comprised of two phases:\n",
    "1. Run a Fourier transform on each scan to move from the time domain to the frequency domain\n",
    "2. Average (in bins of frequency) all scans in a data-taking run, to extract a single frequency scan\n",
    " \n",
    "This procedure is highly parallelizable, and should be implemented in a quasi-online pipeline for two main reasons:\n",
    "1. Monitoring the scans during the data taking to promptly spot and identify possible issues in the detector setup or instabilities in the condition of the experiment\n",
    "2. Data is continuously produced with a very large rate, and the local storage provided by the DAQ server of the QUAX experiment is not really suited for large-volume and long-lasting datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93512045",
   "metadata": {},
   "source": [
    "### 2.1. Pipeline Overview <a name=\"pipeline\"></a>\n",
    "\n",
    "The data processing pipeline will be implemented as follows:\n",
    "- Each pair of files is unpacked according to their schema and split into scans.\n",
    "- Data is produced to a Kafka topic by a stream-emulator script every 5 seconds to simulate the fixed ADC scanning rate and the fixed size of files written to disk. \n",
    "- The processing of each file runs is performed in a distributed framework using pySpark: for each scan, a FFT is executed in parallel and the results of all FFTs are averaged.\n",
    "- The results are re-injected into a new Kafka topic hosted on the same brokers.\n",
    "- A final consumer performs the plotting, displaying live updates of the scans and continuously updating the entire \"run-wide\" scan using bokeh.\n",
    "\n",
    "The overall pipeline can be thus summarised as:\n",
    "![pipeline schema](Images\\Pipeline_Schema2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df89d6e",
   "metadata": {},
   "source": [
    "### 2.2. Kafka - Receiving Data from DAQ <a name=\"kafka\"></a>\n",
    "\n",
    "Apache Kafka is an open-source distributed event streaming platform for high-performance data pipelines, streaming analytics, data integration, and mission-critical applications. As discussed previously, in this work it will be used to handle the live streaming of data from the DAQ servers all the way to the final live plot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5994b58e",
   "metadata": {},
   "source": [
    "#### 2.2.1. Data Topic <a name=\"kafka_topic\"></a>\n",
    "\n",
    "The first step is to create a topic on the broker to hold the data from the DAQ. We create it with 4 separate partitions and no replication. The meaning of the name \"chunk_data\" will be made clear in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3b3c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to the cluster to run admin functions\n",
    "kafka_admin = KafkaAdminClient(\n",
    "    bootstrap_servers=KAFKA_BOOTSTRAP_SERVERS,\n",
    ")\n",
    "\n",
    "# define new topic to hold data\n",
    "topic_in = NewTopic(name='chunk_data',\n",
    "                    num_partitions=4, \n",
    "                    replication_factor=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8fb0f3",
   "metadata": {},
   "source": [
    "#### 2.2.2. Data Preprocessing <a name=\"kafka_preprocessing\"></a>\n",
    "\n",
    "The size of the files produced by the DAQ is 32 MB, which means that each message handled by Kafka should be 64 MB as we need both the real and imaginary componenets. Unfortunately, the default message size in Kafka is only 1 MB. There are of course ways to circumvent this limit, namely:\n",
    " \n",
    "- at the broker level, changing the *replica.fetch.max.bytes* in the broker settings and increasing the *max.message.bytes* for the topic to the desired value\n",
    "- at the consumer level, increasing the *max.partition.fetch.bytes*, otherwise the consumer will fail to fetch these messages and will get stuck on processing\n",
    "- at the producer level, increasing the *max.request.size* to ensure large messages can be sent\n",
    "\n",
    "While this solution is possible, it is still against the philosophy of Kafka: sending large messages is considered inefficient as they should be huge in number but not in size.\n",
    "\n",
    "We thus decided to first unpack the data into slices and send a pair of real and imaginary slices as a message. Since for each FFT we want *n<sub>bins</sub>* = 3 × 2<sup>10</sup> = 3027 bins and we have a total of 8193 × 2<sup>10</sup> samples per file, the amount of slices to compute FFTs on for each file (and thus of mesages to be sent) is\n",
    "\n",
    "$$n_{slices} = \\cfrac{n_{samples}}{n_{bins}} = \\cfrac{8193 \\times 2^{10} }{3 \\times 2^{10}} = 2731$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1aa567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read all data from input files\n",
    "real = bytearray(binary_data_real)\n",
    "imag = bytearray(binary_data_imm)\n",
    "\n",
    "# unpack data\n",
    "for f in range(n_slice):\n",
    "    r_bin = real[4*n_bins*f:4*n_bins*(f+1)] # one float every 4 bytes\n",
    "    i_bin = imag[4*n_bins*f:4*n_bins*(f+1)]\n",
    "    \n",
    "    # create kafka message\n",
    "    msg = r_bin + i_bin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fabe7f",
   "metadata": {},
   "source": [
    "#### 2.2.3. Producer <a name=\"kafka_producer\"></a>\n",
    "\n",
    "Lastly we can initialize the Kafka producer, the one responsible to read data from the files and actually sending it to the correct topic. The message, as descibed before, is given by two consecutives byte arrays containing the real and imaginary slices. The key, instead, contains the number of the file and of the particular slice contained in the message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d92e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Kafka producer instance\n",
    "chunk_producer = KafkaProducer(bootstrap_servers=KAFKA_BOOTSTRAP_SERVERS)\n",
    "\n",
    "\n",
    "def send_chunks(file_paths,dirPath):\n",
    "    \n",
    "    partners = sorted(find_partner(file_paths), key=lambda x: get_number_from_filename(x[0]))\n",
    "    \n",
    "    for couple in partners: \n",
    "        \n",
    "        couple=[dirPath+x for x in couple]\n",
    "        binary_data_real = read_binary_file(couple[0])\n",
    "        binary_data_imm = read_binary_file(couple[1])\n",
    "\n",
    "        real = bytearray(binary_data_real)\n",
    "        imag = bytearray(binary_data_imm)\n",
    "        \n",
    "        file_num=int(couple[0][-9:-4])\n",
    "        \n",
    "        for f in range(n_slice):\n",
    "            \n",
    "            r_bin = real[4*n_bins*f:4*n_bins*(f+1)] # one float every 4 bytes\n",
    "            i_bin = imag[4*n_bins*f:4*n_bins*(f+1)]\n",
    "            msg = r_bin + i_bin\n",
    "        \n",
    "            # key = file + bin number\n",
    "            key = (file_num).to_bytes(2, \"big\") + f.to_bytes(2, \"big\")\n",
    "           \n",
    "            print(\"Sending file\",file_num,\"\\tslice number:\",f+1,end=\"\\r\")\n",
    "            chunk_producer.send(topic = \"chunk_data\",\n",
    "                            key   = key,\n",
    "                            value = msg)\n",
    "            \n",
    "            chunk_producer.flush()  # Flush the producer buffer\n",
    "        \n",
    "        print(\"                                                                 \")\n",
    "        print(\"File\", file_num,\"completed!\")\n",
    "        print(\"------------------------------\")\n",
    "        #time.sleep(5)   # Sleep for a short duration before sending the next message\n",
    "                        # to mimick waiting time for new data\n",
    "        \n",
    "send_chunks(file_paths,folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4979f961",
   "metadata": {},
   "source": [
    "### 2.3. Spark - Distributed Processing <a name=\"spark\"></a>\n",
    "\n",
    "Apache Spark is an open-source unified analytics engine for large-scale data processing. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
