{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d680f76",
   "metadata": {},
   "source": [
    "# Live plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37309c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaConsumer\n",
    "from name import *\n",
    "from bokeh.plotting import figure, show, output_notebook\n",
    "from bokeh.models import ColumnDataSource, RangeSlider\n",
    "from bokeh.layouts import column\n",
    "from bokeh.io import push_notebook\n",
    "from tornado.ioloop import PeriodicCallback\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# create a Kafka consumer instance\n",
    "plot_consumer = KafkaConsumer(\n",
    "    bootstrap_servers=KAFKA_BOOTSTRAP_SERVERS,  # list of Kafka brokers\n",
    "    consumer_timeout_ms=10_000                  # maximum time to wait for a new message \n",
    "                                                # before stopping the consumer\n",
    ")\n",
    "plot_consumer.subscribe('results')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b657c70",
   "metadata": {},
   "source": [
    "## Handling Kafka Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197e99f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_consumer.topics()\n",
    "\n",
    "# Function to split an index string into file number and bin number, returning them as integers\n",
    "def sep_index(index):\n",
    "    file_num, bin_num = index.split('_')\n",
    "    return int(file_num),int(bin_num)\n",
    "\n",
    "# Function to read data from Kafka\n",
    "def read_kafka():\n",
    "    global batch_counter, n_cum\n",
    "    print(f'\\rReading batch: {batch_counter} \\t\\t analysing file: {n_cum}',end='\\r')\n",
    "    \n",
    "    # read latest message\n",
    "    new_data = {}\n",
    "    for message in plot_consumer:\n",
    "        new_data = json.loads(message.value)\n",
    "        break\n",
    "        \n",
    "    batch_counter += 1\n",
    "\n",
    "    # create dictionary to feed to bokeh\n",
    "    # each entry correspinds to a specific file: the key is the file number\n",
    "    # and the value is itself a dictionary containing a list of\n",
    "    # mean values, standard deviations and number of slices used for computing the mean\n",
    "    file_dict = {'mean':n_bins*[0.], 'dev':n_bins*[0.]}\n",
    "\n",
    "    for el in new_data:\n",
    "        file_num, bin_num = sep_index(el['data']['index'])\n",
    "        \n",
    "        file_dict['mean'][bin_num] = el['data']['mean_x']\n",
    "        file_dict['dev'][bin_num] = el['data']['stddev_x']\n",
    "        \n",
    "    \n",
    "    return file_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d796597",
   "metadata": {},
   "source": [
    "## Live Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22ef21e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Initialize the notebook for displaying Bokeh plots\n",
    "output_notebook()\n",
    "\n",
    "# Initialize batch_counter and define the x-axis values\n",
    "FS = fft_bandwidth\n",
    "batch_counter = 0\n",
    "xaxis = np.arange(FS/-2.0, FS/2.0, FS/(n_bins))+ LOFreq\n",
    "\n",
    "# Initialize the file count (n_cum) and the error for the cumulative\n",
    "n_cum = 0\n",
    "cum_sigma = np.zeros(n_bins)\n",
    "\n",
    "# Define data sources for the current batch, the cumulative mean and their error\n",
    "stream_source = ColumnDataSource(data = {'freq': xaxis, 'fft' : n_bins*[0.], 'std' : n_bins*[0.] })\n",
    "err_source = ColumnDataSource(data = {'freq': xaxis, 'y1' : n_bins*[0.], 'y2' : n_bins*[0.] })\n",
    "\n",
    "cumulative_source = ColumnDataSource(data={'freq': xaxis, 'fft': 3072*[0.], 'std': 3072*[0.]})\n",
    "err_cum = ColumnDataSource(data = {'freq': xaxis, 'y1' : n_bins*[0.], 'y2' : n_bins*[0.] })\n",
    "\n",
    "# Create the Bokeh plot\n",
    "plot = figure(width=900, height=450)\n",
    "\n",
    "\n",
    "# Define areas for error shading and lines for data\n",
    "err_fill = plot.varea(x='freq', y1='y1', y2='y2', source=err_source, alpha=.5,\n",
    "                      fill_color='lightblue', legend_label='Std Batch')\n",
    "line = plot.line('freq', 'fft', source=stream_source, legend_label='Current Batch',line_width=2, alpha=.8)\n",
    "\n",
    "err_cum_fill = plot.varea(x='freq', y1='y1', y2='y2', source=err_cum, alpha=.5,\n",
    "                      fill_color='bisque', legend_label='Std Cumulative')\n",
    "cum_line = plot.line('freq', 'fft', source=cumulative_source,\n",
    "                     legend_label='Cumulative', line_width=2, color='orange')\n",
    "\n",
    "# Define a pandas storage for the final results\n",
    "storage = pd.DataFrame({'freq':xaxis,'fft':np.zeros(n_bins), 'std':np.zeros(n_bins)})\n",
    "\n",
    "\n",
    "\n",
    "# Define a callback function to update the plot data\n",
    "def update():\n",
    "    global n_cum, cum_sigma, storage\n",
    "    kafka_data = read_kafka()\n",
    "        \n",
    "    # check if JSON message is not empty\n",
    "    if kafka_data['mean'][0] > 0:\n",
    "        \n",
    "        # Update the single batch\n",
    "        stream_source.data['fft'] = kafka_data['mean']\n",
    "    \n",
    "        # Update the area for the Current Batch error\n",
    "        y = np.array(kafka_data['mean'])\n",
    "        sigma = np.array(kafka_data['dev'])\n",
    "        topline = y + sigma\n",
    "        bottomline = np.where(y - sigma > 0, y - sigma, 0.)\n",
    "    \n",
    "        err_source.data['y1'] = bottomline\n",
    "        err_source.data['y2'] = topline\n",
    "        \n",
    "        \n",
    "        # Update the cumulative\n",
    "        n_cum += 1\n",
    "        cumulative_source.data['fft'] = (n_cum - 1)/n_cum*np.array(cumulative_source.data['fft']) + \\\n",
    "                                                 1/n_cum*np.array(kafka_data['mean'])\n",
    "        \n",
    "        # Update the area for the Current Batch error\n",
    "        cum_y = np.array(cumulative_source.data['fft'])\n",
    "        cum_sigma = 1/n_cum * np.sqrt(( n_cum -1 )**2 * cum_sigma**2 + sigma**2)\n",
    "    \n",
    "        cum_topline = cum_y + cum_sigma\n",
    "        cum_bottomline = np.where(cum_y - cum_sigma > 0, cum_y - cum_sigma, 0.)\n",
    "        \n",
    "        err_cum.data['y1'] = cum_topline\n",
    "        err_cum.data['y2'] = cum_bottomline\n",
    "        \n",
    "        # Update the store Dataframe\n",
    "        storage['fft'] = cum_y\n",
    "        storage['std'] = cum_sigma\n",
    "    \n",
    "   \n",
    "    push_notebook()  # Update the notebook plot\n",
    "\n",
    "# Configure the plot appearance and labels\n",
    "plot.legend.click_policy=\"hide\"\n",
    "plot.xaxis.axis_label = 'Frequency [Hz]'\n",
    "plot.yaxis.axis_label = 'FFT'\n",
    "\n",
    "\n",
    "# Display the plot in the notebook and store the handle for future updates\n",
    "handle = show(column(plot), notebook_handle=True)\n",
    "print('Initializing',end='\\r')\n",
    "\n",
    "\n",
    "# Set up a periodic callback to update the plot every x seconds\n",
    "callback = PeriodicCallback(update, 5_000)  # = 5 seconds\n",
    "callback.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f08399b",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback.stop()\n",
    "storage.to_csv('final_results/run389.csv', index=False)  # Save the final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6154d15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_consumer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
